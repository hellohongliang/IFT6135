{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download mnist dataset with train, validation and test seperation using download.py \n",
    "# from https://github.com/CW-Huang/IFT6135H19_assignment/blob/master/download.py \n",
    "# Make sure the downloaded dataset is with the same directory with this code \n",
    "# Load it as numpy array\n",
    "\n",
    "dataset = np.load('mnist.pkl.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build train, validation and test arrays\n",
    "im_size = (28,28)\n",
    "train_x = np.reshape(dataset[0,0], [-1,1,im_size[0],im_size[1]])\n",
    "train_y = dataset[0,1]\n",
    "\n",
    "validate_x = np.reshape(dataset[1,0], [-1,1,im_size[0],im_size[1]])\n",
    "validate_y = dataset[1,1]\n",
    "\n",
    "test_x = np.reshape(dataset[2,0], [-1,1,im_size[0],im_size[1]])\n",
    "test_y = dataset[2,1]\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "validate_x = torch.from_numpy(validate_x)\n",
    "validate_y = torch.from_numpy(validate_y)\n",
    "\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_y = torch.from_numpy(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "train_dataset = torch.utils.data.TensorDataset(train_x.float(),train_y.float())\n",
    "val_dataset = torch.utils.data.TensorDataset(validate_x.float(),validate_y.float())\n",
    "test_dataset = torch.utils.data.TensorDataset(test_x.float(),test_y.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply torch data loader\n",
    "train_batch_size = 50;\n",
    "val_batch_size = 1000;\n",
    "test_batch_size = 1000;\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = val_batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define numbers of epoch and learning rate\n",
    "num_epochs = 10;\n",
    "learning_rate = 0.01;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a CNN model with five convolutional layers and one linear layer. This architecture refers to the architecture from  \n",
    "# https://github.com/MaximumEntropy/welcome_tutorials/blob/pytorch/pytorch/4.Image Classification with Convnets and ResNets.ipynb\n",
    "# The total numbers of parameters are \n",
    "# (3*3*1+1)*16 + (3*3*16+1)*32 + (3*3*32+1)*64 + (3*3*64+1)*128 + (3*3*128+1)*256  + (256+1)*10 = 394890\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=1),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 5           \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        \n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a instance of the CNN\n",
    "cnn = CNN();\n",
    "if cuda_available:\n",
    "    cnn = cnn.cuda()\n",
    "    \n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate, momentum=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Train loss : 2.090 \n",
      "Epoch : 1 Validation loss : 0.557 \n",
      "Test Accuracy of the model on the 10000 validation images: 83.0000 %\n",
      "Epoch : 2 Train loss : 0.269 \n",
      "Epoch : 2 Validation loss : 0.117 \n",
      "Test Accuracy of the model on the 10000 validation images: 96.0000 %\n",
      "Epoch : 3 Train loss : 0.117 \n",
      "Epoch : 3 Validation loss : 0.098 \n",
      "Test Accuracy of the model on the 10000 validation images: 96.0000 %\n",
      "Epoch : 4 Train loss : 0.082 \n",
      "Epoch : 4 Validation loss : 0.068 \n",
      "Test Accuracy of the model on the 10000 validation images: 97.0000 %\n",
      "Epoch : 5 Train loss : 0.067 \n",
      "Epoch : 5 Validation loss : 0.060 \n",
      "Test Accuracy of the model on the 10000 validation images: 98.0000 %\n",
      "Epoch : 6 Train loss : 0.055 \n",
      "Epoch : 6 Validation loss : 0.078 \n",
      "Test Accuracy of the model on the 10000 validation images: 97.0000 %\n",
      "Epoch : 7 Train loss : 0.047 \n",
      "Epoch : 7 Validation loss : 0.055 \n",
      "Test Accuracy of the model on the 10000 validation images: 98.0000 %\n",
      "Epoch : 8 Train loss : 0.041 \n",
      "Epoch : 8 Validation loss : 0.054 \n",
      "Test Accuracy of the model on the 10000 validation images: 98.0000 %\n",
      "Epoch : 9 Train loss : 0.035 \n",
      "Epoch : 9 Validation loss : 0.050 \n",
      "Test Accuracy of the model on the 10000 validation images: 98.0000 %\n",
      "Epoch : 10 Train loss : 0.033 \n",
      "Epoch : 10 Validation loss : 0.041 \n",
      "Test Accuracy of the model on the 10000 validation images: 98.0000 %\n"
     ]
    }
   ],
   "source": [
    "# Do train and validation test\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "# Train model\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        if cuda_available:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        \n",
    "        labels = labels.long()\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item());\n",
    "\n",
    "    train_loss_list.append(np.mean(train_losses))\n",
    "    print('Epoch : %d Train loss : %.3f ' % (epoch+1, np.mean(train_losses)))\n",
    "    \n",
    "            \n",
    "# Validation test\n",
    "    cnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for (images, labels) in val_loader:\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        labels = labels.long()\n",
    "        \n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_losses.append(loss.item());\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    " \n",
    "        correct += (predicted == labels.data).sum()\n",
    "    \n",
    "    val_loss_list.append(np.mean(val_losses))\n",
    "    print('Epoch : %d Validation loss : %.3f ' % (epoch+1, np.mean(val_losses)))\n",
    "    print('Test Accuracy of the model on the 10000 validation images: %.4f %%' % (100 * correct / total))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train erros of 10 epochs are [2.0898662351071833, 0.26863609709590675, 0.11656876287609338, 0.082333156525855877, 0.066571214697556572, 0.055100712203187865, 0.047392328367102894, 0.040538050214119721, 0.035341240907262546, 0.032806129832955777]\n",
      "========================================================================================================================\n",
      "The validation erros of 10 epochs are [0.5572406023740768, 0.11719357892870903, 0.098012304306030279, 0.067866875417530531, 0.060328469984233378, 0.078000639937818056, 0.055262971483170983, 0.054385329596698284, 0.050006810948252677, 0.041478047519922255]\n"
     ]
    }
   ],
   "source": [
    "# Show train and validation errors\n",
    "print('The train erros of 10 epochs are', train_loss_list)\n",
    "print('========================================================================================================================')\n",
    "print('The validation erros of 10 epochs are', val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and validation error of each epoch\n",
    "x_axis = np.linspace(1, num_epochs, num_epochs)\n",
    "plt.gca().set_prop_cycle(color=['red', 'blue'])\n",
    "plt.plot(x_axis, train_loss_list)\n",
    "plt.plot(x_axis, val_loss_list)\n",
    "#plt.axis(x_axis)\n",
    "plt.xticks(x_axis)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('CNN error')\n",
    "plt.legend(['Train error', 'Validation error'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 99.0000 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model with test dataset\n",
    "cnn.eval()\n",
    "\n",
    "success = 0 # Number of correct prediction\n",
    "total = 0 # Total number of test dataset\n",
    "\n",
    "for (images, labels) in test_loader:\n",
    "    \n",
    "    images, labels = Variable(images), Variable(labels)\n",
    "    labels = labels.long()\n",
    "        \n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += labels.size(0)\n",
    " \n",
    "    # Add correct prediciton to success\n",
    "    success += (predicted == labels.data).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * success / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
